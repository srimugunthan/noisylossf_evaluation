{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO5UK77A8wGm8/1u9zvjuVl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":20,"metadata":{"id":"KYqnMseA3MSD","executionInfo":{"status":"ok","timestamp":1748907411188,"user_tz":-330,"elapsed":7,"user":{"displayName":"Srimugunthan Dhandapani","userId":"08831213363995095166"}}},"outputs":[],"source":["\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","import argparse\n"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","import os\n","os.chdir('/content/drive/My Drive/Colab Notebooks/noisyloss/')\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8g6JO5QddrAL","executionInfo":{"status":"ok","timestamp":1748907413907,"user_tz":-330,"elapsed":1619,"user":{"displayName":"Srimugunthan Dhandapani","userId":"08831213363995095166"}},"outputId":"0861d894-064d-4b71-cbf7-ebb6a8e38100"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["import loss_functions"],"metadata":{"id":"IsQw5W_DgGzu","executionInfo":{"status":"ok","timestamp":1748907417605,"user_tz":-330,"elapsed":8,"user":{"displayName":"Srimugunthan Dhandapani","userId":"08831213363995095166"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["my_agce_loss = loss_functions.agce_loss_fn(num_classes=10, a=4, q=0.21, scale=1.0)"],"metadata":{"id":"KcFJNfzilNk_","executionInfo":{"status":"ok","timestamp":1748907418228,"user_tz":-330,"elapsed":11,"user":{"displayName":"Srimugunthan Dhandapani","userId":"08831213363995095166"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["crentr_loss_fn = loss_functions.crossentropy_reed_wrap(0.3)"],"metadata":{"id":"O44T-Q78gPnU","executionInfo":{"status":"ok","timestamp":1748907419190,"user_tz":-330,"elapsed":9,"user":{"displayName":"Srimugunthan Dhandapani","userId":"08831213363995095166"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["# Example usage:\n","alpha = 0.1\n","beta = 1.0\n","symloss_fn = loss_functions.symmetric_cross_entropy(alpha, beta)"],"metadata":{"id":"MADbCFEUgfCT","executionInfo":{"status":"ok","timestamp":1748907419986,"user_tz":-330,"elapsed":16,"user":{"displayName":"Srimugunthan Dhandapani","userId":"08831213363995095166"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["lq_loss_fn = loss_functions.lq_loss_wrap(0.3)"],"metadata":{"id":"DiLWGDWo_pZT","executionInfo":{"status":"ok","timestamp":1748907421205,"user_tz":-330,"elapsed":14,"user":{"displayName":"Srimugunthan Dhandapani","userId":"08831213363995095166"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["mae_loss_multi_class = loss_functions.mae_loss_multi_class"],"metadata":{"id":"-NlduSejJJhf","executionInfo":{"status":"ok","timestamp":1748907422969,"user_tz":-330,"elapsed":11,"user":{"displayName":"Srimugunthan Dhandapani","userId":"08831213363995095166"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["# from tensorflow.keras.utils import plot_model\n","# from IPython.display import Image, display\n","\n","# # Assuming you have created your model using the create_model function\n","# model = create_model()\n","\n","# # Generate the plot and get the image data\n","# # We set to_file=None to prevent saving to a file and get bytes instead\n","# plot_model(model, show_shapes=True,to_file=\"./model_arch.jpg\")\n"],"metadata":{"id":"QLVKbtplzmal","executionInfo":{"status":"ok","timestamp":1748900450957,"user_tz":-330,"elapsed":17,"user":{"displayName":"Srimugunthan Dhandapani","userId":"08831213363995095166"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["\n","\n","(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n","\n","# Preprocess the data\n","x_train = x_train.astype('float32') / 255.0\n","x_test = x_test.astype('float32') / 255.0\n","x_train = x_train.reshape(-1, 28, 28, 1)\n","x_test = x_test.reshape(-1, 28, 28, 1)"],"metadata":{"id":"DMY0MoAaTqcq","executionInfo":{"status":"ok","timestamp":1748907428986,"user_tz":-330,"elapsed":818,"user":{"displayName":"Srimugunthan Dhandapani","userId":"08831213363995095166"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["\n","def create_model():\n","  model = keras.Sequential([\n","      keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n","      keras.layers.MaxPooling2D(pool_size=(2, 2)),\n","      keras.layers.Conv2D(64, (3, 3), activation='relu'),\n","      keras.layers.MaxPooling2D(pool_size=(2, 2)),\n","      keras.layers.Flatten(),\n","      keras.layers.Dropout(0.5),\n","      keras.layers.Dense(10, activation='softmax')\n","  ])\n","  return model\n"],"metadata":{"id":"STf3X6Rh3VGy","executionInfo":{"status":"ok","timestamp":1748907431272,"user_tz":-330,"elapsed":17,"user":{"displayName":"Srimugunthan Dhandapani","userId":"08831213363995095166"}}},"execution_count":29,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VlbZkqTr0qzE"},"source":["## noisy labels"]},{"cell_type":"code","execution_count":45,"metadata":{"collapsed":true,"id":"tI0TIgK60qzE","executionInfo":{"status":"ok","timestamp":1748913598919,"user_tz":-330,"elapsed":4,"user":{"displayName":"Srimugunthan Dhandapani","userId":"08831213363995095166"}}},"outputs":[],"source":["import numpy as np\n","NOISE_LEVEL=0.4  # what part of training labels are permuted\n","perm = np.array([7, 9, 0, 4, 2, 1, 3, 5, 6, 8])  # noise permutation (from Reed)"]},{"cell_type":"code","execution_count":46,"metadata":{"collapsed":true,"id":"JqS33nVU0qzE","executionInfo":{"status":"ok","timestamp":1748913599530,"user_tz":-330,"elapsed":3,"user":{"displayName":"Srimugunthan Dhandapani","userId":"08831213363995095166"}}},"outputs":[],"source":["noise = perm[y_train]"]},{"cell_type":"code","source":["# replace some of the training labels with permuted (noise) labels.\n","# make sure each categories receive an equal amount of noise\n","\n","\n","from sklearn.model_selection import StratifiedShuffleSplit\n","if NOISE_LEVEL > 0:\n","  _, noise_idx = next(iter(StratifiedShuffleSplit(n_splits=1,\n","                                                  test_size=NOISE_LEVEL,\n","                                                  random_state=42).split(x_train,y_train)))\n","  y_train_noise = y_train.copy()\n","  y_train_noise[noise_idx] = noise[noise_idx]\n","  # break the training set to 10% validation which we will use for early stopping.\n","  train_idx, val_idx = next(iter(\n","          StratifiedShuffleSplit(n_splits=1, test_size=0.1,\n","                                random_state=42).split(x_train, y_train_noise)))\n","  X_train_train = x_train[train_idx]\n","  y_train_correct = y_train[train_idx]\n","  y_train_train = y_train_noise[train_idx]\n","  X_train_val = x_train[val_idx]\n","  y_train_val = y_train_noise[val_idx]\n","  y_train_val_correct = y_train[val_idx]\n","else:\n","  train_idx, val_idx = next(iter(\n","        StratifiedShuffleSplit(n_splits=1, test_size=0.1,\n","                               random_state=42).split(x_train, y_train)))\n","  X_train_train = x_train[train_idx]\n","  y_train_train = y_train[train_idx]\n","  y_train_correct = y_train[train_idx]\n","  X_train_val = x_train[val_idx]\n","  y_train_val = y_train[val_idx]\n","  y_train_val_correct = y_train[val_idx]\n","\n","\n","\n"],"metadata":{"id":"OcqdhPMead1Z","executionInfo":{"status":"ok","timestamp":1748913600548,"user_tz":-330,"elapsed":482,"user":{"displayName":"Srimugunthan Dhandapani","userId":"08831213363995095166"}}},"execution_count":47,"outputs":[]},{"cell_type":"code","source":["\n","\n","from keras.callbacks import EarlyStopping\n","from sklearn import metrics\n","\n","model = create_model()\n","model.compile(optimizer='adam',\n","                    loss=my_agce_loss,\n","                    metrics=['accuracy'])\n","\n","history = model.fit(X_train_train,\n","                      y_train_train,\n","                      batch_size=512,\n","                      epochs=10,\n","                      verbose=True,\n","                      validation_data=(X_train_val,\n","                                      y_train_val_correct),\n","                      callbacks=\n","                      [EarlyStopping(patience=4,mode='min',\n","                                    verbose=True)]\n","                      )\n","\n","# Evaluate the model\n","#loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n","#y_pred = model.predict(x_test)\n","y_pred_probs = model.predict(x_test)  # Get predicted probabilities\n","y_pred = np.argmax(y_pred_probs, axis=1)  # Convert probabilities to class labels\n","\n","\n","\n","acc = metrics.accuracy_score(y_test, y_pred)\n","macro_averaged_f1 = metrics.f1_score(y_test, y_pred, average = 'macro')\n","print(\"accuracy\",acc)\n","print(\"macro_f1\",macro_averaged_f1)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rHNT7gLpdH-D","outputId":"248ebc47-bb70-4370-b580-e15fb75ff8ae"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","\u001b[1m 77/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 413ms/step - accuracy: 0.2325 - loss: 0.2686"]}]},{"cell_type":"code","source":["\n","import matplotlib.pyplot as plt\n","\n","plt.figure(figsize=(12, 5))\n","\n","# Plot training & validation accuracy values\n","plt.subplot(1, 2, 1)\n","plt.plot(history.history['accuracy'])\n","plt.plot(history.history['val_accuracy'])\n","plt.title('Model Accuracy')\n","plt.ylabel('Accuracy')\n","plt.xlabel('Epoch')\n","plt.legend(['Train', 'Validation'], loc='upper left')\n","\n","# Plot training & validation loss values\n","plt.subplot(1, 2, 2)\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('Model Loss')\n","plt.ylabel('Loss')\n","plt.xlabel('Epoch')\n","plt.legend(['Train', 'Validation'], loc='upper left')\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"APU5RpI3cj7z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(NOISE_LEVEL)"],"metadata":{"id":"NQFmz_rZ2lV8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import StratifiedShuffleSplit\n","\n","from keras.callbacks import EarlyStopping\n","from sklearn import metrics\n","import numpy as np\n","\n","seeds = [42, 123, 456]\n","all_results = []\n","\n","for seed in seeds:\n","    print(f\"Running with seed: {seed}\")\n","    tf.random.set_seed(seed)\n","    np.random.seed(seed) # Set numpy seed as well\n","\n","\n","    if NOISE_LEVEL > 0:\n","      _, noise_idx = next(iter(StratifiedShuffleSplit(n_splits=1,\n","                                                      test_size=NOISE_LEVEL,\n","                                                      random_state=seed).split(x_train,y_train)))\n","      y_train_noise = y_train.copy()\n","      y_train_noise[noise_idx] = noise[noise_idx]\n","      # break the training set to 10% validation which we will use for early stopping.\n","      train_idx, val_idx = next(iter(\n","              StratifiedShuffleSplit(n_splits=1, test_size=0.1,\n","                                    random_state=seed).split(x_train, y_train_noise)))\n","      X_train_train = x_train[train_idx]\n","      y_train_correct = y_train[train_idx]\n","      y_train_train = y_train_noise[train_idx]\n","      X_train_val = x_train[val_idx]\n","      y_train_val = y_train_noise[val_idx]\n","      y_train_val_correct = y_train[val_idx]\n","    else:\n","      train_idx, val_idx = next(iter(\n","            StratifiedShuffleSplit(n_splits=1, test_size=0.1,\n","                                  random_state=seed).split(x_train, y_train)))\n","      X_train_train = x_train[train_idx]\n","      y_train_train = y_train[train_idx]\n","      y_train_correct = y_train[train_idx]\n","      X_train_val = x_train[val_idx]\n","      y_train_val = y_train[val_idx]\n","      y_train_val_correct = y_train[val_idx]\n","\n","    model = create_model()\n","    model.compile(optimizer='adam',\n","                        loss=my_agce_loss,\n","                        metrics=['accuracy'])\n","\n","    train_res = model.fit(X_train_train,\n","                          y_train_train,\n","                          batch_size=512,\n","                          epochs=10,\n","                          verbose=True,\n","                          validation_data=(X_train_val,\n","                                          y_train_val_correct),\n","                          callbacks=\n","                          [EarlyStopping(patience=4,mode='min',\n","                                        verbose=True)]\n","                          )\n","\n","    # Evaluate the model\n","    #loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n","    #y_pred = model.predict(x_test)\n","    y_pred_probs = model.predict(x_test)  # Get predicted probabilities\n","    y_pred = np.argmax(y_pred_probs, axis=1)  # Convert probabilities to class labels\n","\n","    acc = metrics.accuracy_score(y_test, y_pred)\n","    macro_averaged_f1 = metrics.f1_score(y_test, y_pred, average = 'macro')\n","    all_results.append(acc)\n","    print(\"accuracy\",acc)\n","    print(\"macro_f1\",macro_averaged_f1)\n","\n","\n","mean_accuracy = np.mean(all_results)\n","std_accuracy = np.std(all_results)\n","\n","print(f\"Mean accuracy: {mean_accuracy:.4f} +/- {std_accuracy:.4f}\")"],"metadata":{"id":"l7vxFawBuY6c"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":36,"metadata":{"id":"b26D_UnB0qzF","executionInfo":{"status":"ok","timestamp":1748910285055,"user_tz":-330,"elapsed":11,"user":{"displayName":"Srimugunthan Dhandapani","userId":"08831213363995095166"}}},"outputs":[],"source":[]},{"cell_type":"code","source":["\n","\n","# from keras.callbacks import EarlyStopping\n","# from sklearn import metrics\n","\n","# func_dict = {\n","#     \"sparse_categorical_crossentropy\":\"sparse_categorical_crossentropy\",\n","#     \"crossentropy_max_wrap\": c_mwrap_lossfn,\n","#     \"lq_loss_wrap\": lq_loss_fn,\n","#     \"symmetric_cross_entropy\": symloss_fn,\n","#     \"crossentropy_reed_wrap\": crentr_loss_fn,\n","#     \"noise_aware_loss\":noise_aware_loss\n","\n","# }\n","\n","# data_dict = []\n","# for loss_func_name in func_dict.keys():\n","#     lossfunction = func_dict[loss_func_name]\n","#     model = create_model()\n","#     model.compile(optimizer='adam',\n","#                     loss=lossfunction,\n","#                     metrics=['accuracy'])\n","\n","#     # Train the model\n","#     #model.fit(x_train, y_train, epochs=5)\n","\n","#     train_res = model.fit(X_train_train,\n","#                           y_train_train,\n","#                           batch_size=512,\n","#                           epochs=5,\n","#                           verbose=True,\n","#                           validation_data=(X_train_val,\n","#                                           y_train_val),\n","#                           callbacks=\n","#                           [EarlyStopping(patience=4,mode='min',\n","#                                         verbose=True)]\n","#                           )\n","\n","#     # Evaluate the model\n","#     #loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n","#     #y_pred = model.predict(x_test)\n","#     y_pred_probs = model.predict(x_test)  # Get predicted probabilities\n","#     y_pred = np.argmax(y_pred_probs, axis=1)  # Convert probabilities to class labels\n","\n","\n","\n","#     acc = metrics.accuracy_score(y_test, y_pred)\n","#     macro_averaged_f1 = metrics.f1_score(y_test, y_pred, average = 'macro')\n","\n","#     rec = {'lossfunc': loss_func_name, 'acc': acc, 'macro_f1':macro_averaged_f1 }\n","#     data_dict.append(rec.copy())\n","\n","\n"],"metadata":{"id":"xYyuJPpI3ZH4","executionInfo":{"status":"ok","timestamp":1748910285067,"user_tz":-330,"elapsed":11,"user":{"displayName":"Srimugunthan Dhandapani","userId":"08831213363995095166"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["# import pandas as pd\n","# res_df = pd.DataFrame(data_dict)\n","# res_df"],"metadata":{"id":"Zkq-7ojY5jVl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"MpfvuaJJ3gZW"},"execution_count":null,"outputs":[]}]}