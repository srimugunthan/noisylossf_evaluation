{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":13883,"status":"ok","timestamp":1748530113986,"user":{"displayName":"Srimugunthan Dhandapani","userId":"08831213363995095166"},"user_tz":-330},"id":"KYqnMseA3MSD"},"outputs":[],"source":["\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","import argparse\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23625,"status":"ok","timestamp":1748530137585,"user":{"displayName":"Srimugunthan Dhandapani","userId":"08831213363995095166"},"user_tz":-330},"id":"8g6JO5QddrAL","outputId":"0dab517a-ce59-4f32-e0b4-ecceecd630d6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","import os\n","os.chdir('/content/drive/My Drive/Colab Notebooks/noisyloss/')\n","\n","\n"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":1648,"status":"ok","timestamp":1748530139234,"user":{"displayName":"Srimugunthan Dhandapani","userId":"08831213363995095166"},"user_tz":-330},"id":"IsQw5W_DgGzu"},"outputs":[],"source":["import loss_functions"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1748530154010,"user":{"displayName":"Srimugunthan Dhandapani","userId":"08831213363995095166"},"user_tz":-330},"id":"O44T-Q78gPnU"},"outputs":[],"source":["# crentr_loss_fn = loss_functions.crossentropy_reed_wrap(0.3)\n","# # Example usage:\n","# alpha = 0.1\n","# beta = 1.0\n","# symloss_fn = loss_functions.symmetric_cross_entropy(alpha, beta)\n","# lq_loss_fn = loss_functions.lq_loss_wrap(0.3)"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1748530156256,"user":{"displayName":"Srimugunthan Dhandapani","userId":"08831213363995095166"},"user_tz":-330},"id":"MADbCFEUgfCT"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DiLWGDWo_pZT"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1748530163056,"user":{"displayName":"Srimugunthan Dhandapani","userId":"08831213363995095166"},"user_tz":-330},"id":"QLVKbtplzmal"},"outputs":[],"source":["# from tensorflow.keras.utils import plot_model\n","# from IPython.display import Image, display\n","\n","# # Assuming you have created your model using the create_model function\n","# model = create_model()\n","\n","# # Generate the plot and get the image data\n","# # We set to_file=None to prevent saving to a file and get bytes instead\n","# plot_model(model, show_shapes=True,to_file=\"./model_arch.jpg\")\n"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":696,"status":"ok","timestamp":1748530165875,"user":{"displayName":"Srimugunthan Dhandapani","userId":"08831213363995095166"},"user_tz":-330},"id":"DMY0MoAaTqcq","outputId":"d61d7fb7-5b1b-4b65-fa13-c1392050da64"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"]}],"source":["loss_param ='sparse_categorical_crossentropy'\n","\n","(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n","\n","# Preprocess the data\n","x_train = x_train.astype('float32') / 255.0\n","x_test = x_test.astype('float32') / 255.0\n","x_train = x_train.reshape(-1, 28, 28, 1)\n","x_test = x_test.reshape(-1, 28, 28, 1)"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1748530167867,"user":{"displayName":"Srimugunthan Dhandapani","userId":"08831213363995095166"},"user_tz":-330},"id":"STf3X6Rh3VGy"},"outputs":[],"source":["\n","def create_model():\n","  model = keras.Sequential([\n","      keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n","      keras.layers.MaxPooling2D(pool_size=(2, 2)),\n","      keras.layers.Conv2D(64, (3, 3), activation='relu'),\n","      keras.layers.MaxPooling2D(pool_size=(2, 2)),\n","      keras.layers.Flatten(),\n","      keras.layers.Dropout(0.5),\n","      keras.layers.Dense(10, activation='softmax')\n","  ])\n","  return model\n"]},{"cell_type":"markdown","metadata":{"id":"VlbZkqTr0qzE"},"source":["## noisy labels"]},{"cell_type":"code","execution_count":8,"metadata":{"collapsed":true,"executionInfo":{"elapsed":15,"status":"ok","timestamp":1748530175821,"user":{"displayName":"Srimugunthan Dhandapani","userId":"08831213363995095166"},"user_tz":-330},"id":"tI0TIgK60qzE"},"outputs":[],"source":["import numpy as np\n","NOISE_LEVEL=0.6  # what part of training labels are permuted\n","perm = np.array([7, 9, 0, 4, 2, 1, 3, 5, 6, 8])  # noise permutation (from Reed)"]},{"cell_type":"code","execution_count":9,"metadata":{"collapsed":true,"executionInfo":{"elapsed":8,"status":"ok","timestamp":1748530177340,"user":{"displayName":"Srimugunthan Dhandapani","userId":"08831213363995095166"},"user_tz":-330},"id":"JqS33nVU0qzE"},"outputs":[],"source":["noise = perm[y_train]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OcqdhPMead1Z"},"outputs":[],"source":["# replace some of the training labels with permuted (noise) labels.\n","# make sure each categories receive an equal amount of noise\n","\n","\n","from sklearn.model_selection import StratifiedShuffleSplit\n","if NOISE_LEVEL \u003e 0:\n","    _, noise_idx = next(iter(StratifiedShuffleSplit(n_splits=1,\n","                                                    test_size=NOISE_LEVEL,\n","                                                    random_state=seed).split(x_train,y_train)))\n","    y_train_noise = y_train.copy()\n","    y_train_noise[noise_idx] = noise[noise_idx]\n","    train_idx, val_idx = next(iter(\n","            StratifiedShuffleSplit(n_splits=1, test_size=0.1,\n","                                  random_state=seed).split(x_train, y_train_noise)))\n","    X_train_train = x_train[train_idx]\n","    y_train_correct = y_train[train_idx]\n","    y_train_train = y_train_noise[train_idx]\n","    X_train_val = x_train[val_idx]\n","    y_train_val = y_train_noise[val_idx]\n","    y_train_val_correct = y_train[val_idx]\n","else:\n","    train_idx, val_idx = next(iter(\n","          StratifiedShuffleSplit(n_splits=1, test_size=0.1,\n","                                  random_state=seed).split(x_train, y_train)))\n","    X_train_train = x_train[train_idx]\n","    y_train_train = y_train[train_idx]\n","    y_train_correct = y_train[train_idx]\n","    X_train_val = x_train[val_idx]\n","    y_train_val = y_train[val_idx]\n","    y_train_val_correct = y_train[val_idx]"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":3818,"status":"ok","timestamp":1748530206187,"user":{"displayName":"Srimugunthan Dhandapani","userId":"08831213363995095166"},"user_tz":-330},"id":"2f9ff82d"},"outputs":[],"source":["from hyperopt import hp, fmin, tpe, Trials\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from sklearn.model_selection import StratifiedShuffleSplit\n","from sklearn import metrics\n","\n","# Define the search space\n","space = {\n","    'learning_rate': hp.loguniform('learning_rate', np.log(0.0001), np.log(0.01)),\n","    'batch_size': hp.choice('batch_size', [ 128, 256, 512]),\n","    'agce_loss_param_a' :  hp.choice('agce_loss_param_a', [3,4,5]),\n","    'agce_loss_param_q' :  hp.uniform('agce_loss_param_q', 0.1, 0.5),\n","    'epochs': 10 # Fixed number of epochs for each trial\n","}"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":24,"status":"ok","timestamp":1748530294707,"user":{"displayName":"Srimugunthan Dhandapani","userId":"08831213363995095166"},"user_tz":-330},"id":"5cd74663"},"outputs":[],"source":["def objective(params):\n","    # Set seeds for reproducibility within each trial\n","    seed = 42\n","    tf.random.set_seed(seed)\n","    np.random.seed(seed)\n","\n","    # Create the model with hyperparameters from the search space\n","    model = create_model()\n","\n","\n","    my_agce_loss = loss_functions.agce_loss_fn(num_classes=10, a=params['agce_loss_param_a'], q=params['agce_loss_param_q'], scale=1.0)\n","    # Compile the model\n","    optimizer = tf.keras.optimizers.Adam(learning_rate=params['learning_rate'])\n","    model.compile(optimizer=optimizer,\n","                  loss=my_agce_loss,\n","                  metrics=['accuracy'])\n","\n","\n","    # Train the model\n","    history = model.fit(X_train_train,\n","                        y_train_train,\n","                        batch_size=int(params['batch_size']),\n","                        epochs=params['epochs'],\n","                        verbose=0, # Set verbose to 0 to reduce output during tuning\n","                        validation_data=(X_train_val, y_train_val_correct),\n","                        callbacks=[keras.callbacks.EarlyStopping(patience=4, mode='min', verbose=0)]\n","                        )\n","\n","    # Evaluate the model on the validation set and return the loss\n","    val_loss = history.history['val_loss'][-1]\n","    val_accuracy = history.history['val_accuracy'][-1]\n","    return val_loss"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"output_embedded_package_id":"18adBjFJb5_o11KVvj4x2iy0Uc5c_nXsL"},"id":"dc5ca54b","outputId":"681c9336-72f7-4a2f-af4f-05e0131a0c5a"},"outputs":[],"source":["# Run the optimization\n","trials = Trials()\n","best = fmin(fn=objective,\n","            space=space,\n","            algo=tpe.suggest,\n","            max_evals=20, # Number of trials\n","            trials=trials)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t0qkBJAUg0QI"},"outputs":[],"source":["\n","print(\"Best hyperparameters found:\")\n","print(best)\n","\n","\n","\n","\n","best_params = {\n","    'learning_rate': best['learning_rate'],\n","    'batch_size': space['batch_size'][best['batch_size']], # Get the actual value from the choice list\n","    'agce_loss_param_a': space['agce_loss_param_a'][best['agce_loss_param_a']], # Get the actual value from the choice list\n","    'agce_loss_param_q': best['agce_loss_param_q'],\n","    'epochs': 10 # Use the same number of epochs as in the objective function\n","}\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3riYbXT0maUx"},"outputs":[],"source":["\n","\n","from keras.callbacks import EarlyStopping\n","from sklearn import metrics\n","\n","model = create_model()\n","optimizer = tf.keras.optimizers.Adam(learning_rate=best_params['learning_rate'])\n","my_agce_loss = loss_functions.agce_loss_fn(num_classes=10, a=best_params['agce_loss_param_a'], q=best_params['agce_loss_param_q'], scale=1.0)\n","model.compile(optimizer=optimizer,\n","                    loss=my_agce_loss,\n","                    metrics=['accuracy'])\n","\n","history = model.fit(X_train_train,\n","                      y_train_train,\n","                      batch_size=best_params[\"batch_size\"],\n","                      epochs=best_params[\"epochs\"],\n","                      verbose=True,\n","                      validation_data=(X_train_val,\n","                                      y_train_val_correct),\n","                      callbacks=\n","                      [EarlyStopping(patience=4,mode='min',\n","                                    verbose=True)]\n","                      )\n","\n","# Evaluate the model\n","#loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n","#y_pred = model.predict(x_test)\n","y_pred_probs = model.predict(x_test)  # Get predicted probabilities\n","y_pred = np.argmax(y_pred_probs, axis=1)  # Convert probabilities to class labels\n","\n","\n","\n","acc = metrics.accuracy_score(y_test, y_pred)\n","macro_averaged_f1 = metrics.f1_score(y_test, y_pred, average = 'macro')\n","print(\"accuracy\",acc)\n","print(\"macro_f1\",macro_averaged_f1)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YYJaVAJfma3r"},"outputs":[],"source":["\n","import matplotlib.pyplot as plt\n","\n","plt.figure(figsize=(12, 5))\n","\n","# Plot training \u0026 validation accuracy values\n","plt.subplot(1, 2, 1)\n","plt.plot(history.history['accuracy'])\n","plt.plot(history.history['val_accuracy'])\n","plt.title('Model Accuracy')\n","plt.ylabel('Accuracy')\n","plt.xlabel('Epoch')\n","plt.legend(['Train', 'Validation'], loc='upper left')\n","\n","# Plot training \u0026 validation loss values\n","plt.subplot(1, 2, 2)\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('Model Loss')\n","plt.ylabel('Loss')\n","plt.xlabel('Epoch')\n","plt.legend(['Train', 'Validation'], loc='upper left')\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p8ZXt5uqwTIX"},"outputs":[],"source":["from sklearn.model_selection import StratifiedShuffleSplit\n","\n","from keras.callbacks import EarlyStopping\n","from sklearn import metrics\n","import numpy as np\n","\n","seeds = [42, 123, 456]\n","all_results = []\n","\n","for seed in seeds:\n","    print(f\"Running with seed: {seed}\")\n","    tf.random.set_seed(seed)\n","    np.random.seed(seed) # Set numpy seed as well\n","\n","\n","    if NOISE_LEVEL \u003e 0:\n","        _, noise_idx = next(iter(StratifiedShuffleSplit(n_splits=1,\n","                                                        test_size=NOISE_LEVEL,\n","                                                        random_state=seed).split(x_train,y_train)))\n","        y_train_noise = y_train.copy()\n","        y_train_noise[noise_idx] = noise[noise_idx]\n","        train_idx, val_idx = next(iter(\n","                StratifiedShuffleSplit(n_splits=1, test_size=0.1,\n","                                      random_state=seed).split(x_train, y_train_noise)))\n","        X_train_train = x_train[train_idx]\n","        y_train_correct = y_train[train_idx]\n","        y_train_train = y_train_noise[train_idx]\n","        X_train_val = x_train[val_idx]\n","        y_train_val = y_train_noise[val_idx]\n","        y_train_val_correct = y_train[val_idx]\n","    else:\n","        train_idx, val_idx = next(iter(\n","              StratifiedShuffleSplit(n_splits=1, test_size=0.1,\n","                                      random_state=seed).split(x_train, y_train)))\n","        X_train_train = x_train[train_idx]\n","        y_train_train = y_train[train_idx]\n","        y_train_correct = y_train[train_idx]\n","        X_train_val = x_train[val_idx]\n","        y_train_val = y_train[val_idx]\n","        y_train_val_correct = y_train[val_idx]\n","\n","    model = create_model()\n","    optimizer = tf.keras.optimizers.Adam(learning_rate=best_params['learning_rate'])\n","    my_agce_loss = loss_functions.agce_loss_fn(num_classes=10, a=best_params['agce_loss_param_a'], q=best_params['agce_loss_param_q'], scale=1.0)\n","    model.compile(optimizer=optimizer,\n","                        loss=my_agce_loss,\n","                        metrics=['accuracy'])\n","\n","    history = model.fit(X_train_train,\n","                          y_train_train,\n","                          batch_size=best_params[\"batch_size\"],\n","                          epochs=best_params[\"epochs\"],\n","                          verbose=True,\n","                          validation_data=(X_train_val,\n","                                          y_train_val_correct),\n","                          callbacks=\n","                          [EarlyStopping(patience=4,mode='min',\n","                                        verbose=True)]\n","                          )\n","\n","\n","    # Evaluate the model\n","    #loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n","    #y_pred = model.predict(x_test)\n","    y_pred_probs = model.predict(x_test)  # Get predicted probabilities\n","    y_pred = np.argmax(y_pred_probs, axis=1)  # Convert probabilities to class labels\n","\n","    acc = metrics.accuracy_score(y_test, y_pred)\n","    macro_averaged_f1 = metrics.f1_score(y_test, y_pred, average = 'macro')\n","    all_results.append(acc)\n","    print(\"accuracy\",acc)\n","    print(\"macro_f1\",macro_averaged_f1)\n","\n","\n","mean_accuracy = np.mean(all_results)\n","std_accuracy = np.std(all_results)\n","\n","print(f\"Mean accuracy: {mean_accuracy:.4f} +/- {std_accuracy:.4f}\")"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOvgFm1yfFt5q36VcYpVSRq","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}