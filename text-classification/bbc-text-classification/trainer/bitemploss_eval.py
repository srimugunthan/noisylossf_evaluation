# -*- coding: utf-8 -*-
"""Multiclass_Text_Classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Bl8DWCEObKLntOIpLhO45hm3tCXDwFH9

# **Import librares**
"""

# Commented out IPython magic to ensure Python compatibility.

import pandas as pd
import nltk

nltk.download('stopwords')
nltk.download('wordnet')
nltk.download('omw-1.4')
nltk.download('gutenberg')
nltk.download('brown')
nltk.download("reuters")
nltk.download('words')
import tensorflow as tf
from nltk.corpus import stopwords
from nltk.tokenize import RegexpTokenizer
from nltk.stem import SnowballStemmer
import matplotlib.pyplot as plt

from textblob import Word
from sklearn.model_selection import train_test_split
import numpy as np
import re



from tensorflow.keras.preprocessing.text import Tokenizer



from tensorflow.keras.models import Sequential
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau

from tensorflow.keras.preprocessing.sequence import pad_sequences

from tensorflow.keras.layers import Dense, Embedding, LSTM, SpatialDropout1D, Dropout, Flatten, GRU, Conv1D, MaxPooling1D, Bidirectional

#https://www.kaggle.com/datasets/sainijagjit/bbc-dataset?select=bbc-text.csv
#!git clone https://github.com/srimugunthan/bbc-text-classification.git



def bi_tempered_logistic_loss(t1=1.0, t2=1.0):
    """
    Bi-Tempered Logistic Loss for Keras, with t1 and t2 as top-level parameters.

    Args:
        t1 (float): Temperature parameter 1.
        t2 (float): Temperature parameter 2.

    Returns:
        function: A loss function that takes y_true, y_pred, and num_iters.
    """
    def bi_tempered_loss_fn(y_true, y_pred, num_iters=5):
        """
        Inner bi-tempered logistic loss function.

        Args:
            y_true (tf.Tensor): True labels (one-hot encoded or integer).
            y_pred (tf.Tensor): Predicted logits (raw scores before softmax).
            num_iters (int, optional): Number of iterations for numerical stability. Defaults to 5.

        Returns:
            tf.Tensor: Bi-tempered loss.
        """
        y_true = tf.cast(y_true, tf.float32)
        y_pred = tf.cast(y_pred, tf.float32)

        if len(y_true.shape) == len(y_pred.shape) - 1:
            y_true = tf.one_hot(tf.cast(y_true, dtype=tf.int32), depth=tf.shape(y_pred)[-1])
            y_true = tf.cast(y_true, tf.float32)

        # These helper functions can be nested further or defined outside
        # but within the scope of bi_tempered_logistic_loss_nested for clarity
        def log_t(u, t):
            if t == 1.0:
                return tf.math.log(tf.clip_by_value(u, 1e-8, 1.0))
            else:
                return (tf.pow(u, 1.0 - t) - 1.0) / (1.0 - t)

        def exp_t(u, t):
            if t == 1.0:
                return tf.math.exp(tf.clip_by_value(u, -100.0, 100.0))
            else:
                return tf.clip_by_value(1.0 + (1.0 - t) * u, 1e-6, 1e6)**(1.0 / (1.0 - t))

        probs = tf.nn.softmax(y_pred)
        probs_clipped = tf.clip_by_value(probs, 1e-8, 1.0)

        # Calculate loss components using the outer t1 and t2
        loss1 = (1.0 - tf.reduce_sum(y_true * tf.pow(probs_clipped, (1.0 - t1)), axis=-1)) / (1.0 - t1)
        loss2 = (1.0 - tf.reduce_sum(y_true * tf.pow(probs_clipped, (1.0 - t2)), axis=-1)) / (1.0 - t2)

        return tf.reduce_mean(0.5 * (loss1 + loss2))

    return bi_tempered_loss_fn



def preprocess_text(text):

    text = re.sub('[^a-zA-Z]', ' ', text)

    words = text.lower().split()

    words = [stemmer.stem(word) for word in words if not word in stop_words]

    cleaned_text = ' '.join(words)
    return cleaned_text

def create_lstm2_model(vocabulary_size, input_text_len, epochs=12, emb_dim=50, batch_size=128):
    """Creates and compiles a 2-layer Bidirectional LSTM model.

    Args:
        vocabulary_size (int): The size of the vocabulary.
        max_text_len (int): The maximum length of the input sequences.
        epochs (int, optional): The number of training epochs. Defaults to 12.
        emb_dim (int, optional): The embedding dimension. Defaults to 50.
        batch_size (int, optional): The batch size. Defaults to 128.

    Returns:
        keras.models.Sequential: The compiled Keras model.
    """
    model = Sequential()
    model.add(Embedding(vocabulary_size, emb_dim, input_length=input_text_len))
    model.add(SpatialDropout1D(0.8))
    model.add(Bidirectional(LSTM(200, dropout=0.5, recurrent_dropout=0.5, return_sequences=True)))
    model.add(Dropout(0.5))
    model.add(Bidirectional(LSTM(300, dropout=0.5, recurrent_dropout=0.5)))
    model.add(Dropout(0.5))
    model.add(Flatten())
    model.add(Dense(64, activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(5, activation='softmax'))

    return model


def plot_training_history(history, model_name):
    """Plots the training and validation accuracy and loss over epochs.

    Args:
        history (keras.callbacks.History): The history object returned by model.fit().
        model_name (str): The name of the model to be used in the plot titles.
    """
    acc = history.history['acc']
    val_acc = history.history['val_acc']
    loss = history.history['loss']
    val_loss = history.history['val_loss']

    plt.plot(acc, 'go', label='Train accuracy')
    plt.plot(val_acc, 'g', label='Validate accuracy')
    plt.title(f'Train and validate accuracy for {model_name}')
    plt.legend()

    plt.figure()

    plt.plot(loss, 'go', label='Train loss')
    plt.plot(val_loss, 'g', label='Validate loss')
    plt.title(f'Train and validate loss for {model_name}')
    plt.legend()

    plt.show()




if __name__ == "__main__":

    """### **Load Dataset**"""

    print("GPU configs:")
    print(tf.config.list_physical_devices('GPU'))
    my_bitemp_loss = bi_tempered_logistic_loss(t1=0.5,t2=0.4)


    #df=pd.read_csv("./bbc-text-classification/data/bbc-text.csv", engine='python', encoding='UTF-8')
    df = pd.read_csv("gs://textclassification-463913-bucket/bbc-text.csv")
    df['category'].value_counts()
    """# **Data Cleaning**"""

    df['text']=df['text'].fillna("")
    df.isna().sum()

    """# **Preprocessing**"""
    df['lower_case'] = df['text'].apply(lambda x: x.lower().strip().replace('\n', ' ').replace('\r', ' '))

    df['alphabatic'] = df['lower_case'].apply(lambda x: re.sub(r'[^a-zA-Z\']', ' ', x)).apply(lambda x: re.sub(r'[^\x00-\x7F]+', '', x))
    df['without-link'] = df['alphabatic'].apply(lambda x: re.sub(r'http\S+', '', x))

    tokenizer = RegexpTokenizer(r'\w+')
    df['Special_word'] = df.apply(lambda row: tokenizer.tokenize(row['lower_case']), axis=1)

    stop = [word for word in stopwords.words('english') if word not in ["my","haven't","aren't","can","no", "why", "through", "herself", "she", "he", "himself", "you", "you're", "myself", "not", "here", "some", "do", "does", "did", "will", "don't", "doesn't", "didn't", "won't", "should", "should've", "couldn't", "mightn't", "mustn't", "shouldn't", "hadn't", "wasn't", "wouldn't"]]

    df['stop_words'] = df['Special_word'].apply(lambda x: [item for item in x if item not in stop])
    df['stop_words'] = df['stop_words'].astype('str')

    df['short_word'] = df['stop_words'].str.findall('\w{2,}')
    df['string']=df['short_word'].str.join(' ')

    df['Text'] = df['string'].apply(lambda x: " ".join([Word(word).lemmatize() for word in x.split()]))

    print(df.head())

    """# **Deep Learning Models**"""

    vocabulary_size = 15000
    max_text_len = 768
    stemmer = SnowballStemmer('english')
    stop_words = [word for word in stopwords.words('english') if word not in ["my","haven't","aren't","can","no", "why", "through", "herself", "she", "he", "himself", "you", "you're", "myself", "not", "here", "some", "do", "does", "did", "will", "don't", "doesn't", "didn't", "won't", "should", "should've", "couldn't", "mightn't", "mustn't", "shouldn't", "hadn't", "wasn't", "wouldn't"]]

    df['cleaned_text'] = df['text'].apply(preprocess_text)

    tokenizer = Tokenizer(num_words=vocabulary_size)
    tokenizer.fit_on_texts(df['cleaned_text'].values)
    le = len(tokenizer.word_index) + 1
    print(le)
    sequences = tokenizer.texts_to_sequences(df['cleaned_text'].values)
    X_DeepLearning = pad_sequences(sequences, maxlen=max_text_len)

    df['category'].unique()

    df.loc[df['category'] == 'sport' , 'LABEL'] = 0
    df.loc[df['category'] == 'business', 'LABEL'] = 1
    df.loc[df['category'] == 'politics' , 'LABEL'] = 2
    df.loc[df['category'] == 'tech', 'LABEL'] = 3
    df.loc[df['category'] == 'entertainment', 'LABEL'] = 4

    labels = df['LABEL']



    seeds = [42, 123, 456]
    all_results = []

    for seed in seeds:
        print(f"Running with seed: {seed}")
        tf.random.set_seed(seed)
        np.random.seed(seed) # Set numpy seed as well

        XX_train_val, XX_test, y_train_val, y_test = train_test_split(X_DeepLearning , labels.values, test_size=0.2, random_state=seed,stratify=labels)

        print((XX_train_val.shape,  y_train_val.shape,XX_test.shape, y_test.shape))
        y_train_val =y_train_val.astype(int)
        y_test = y_test.astype(int)
        print((XX_train_val.shape,  y_train_val.shape,XX_test.shape, y_test.shape))
        NOISE_LEVEL=0.4 # what part of training labels are permuted
        perm = np.array([3, 2, 0, 4, 1])  # noise permutation (from Reed)
        noise = perm[y_train_val]
        print((XX_train_val.shape,  y_train_val.shape,XX_test.shape, y_test.shape,noise.shape))




        from sklearn.model_selection import StratifiedShuffleSplit
        if NOISE_LEVEL > 0:
            _, noise_idx = next(iter(StratifiedShuffleSplit(n_splits=1,
                                                            test_size=NOISE_LEVEL,
                                                            random_state=seed).split(XX_train_val,y_train_val)))
            y_train_noise = y_train_val.copy()
            y_train_noise[noise_idx] = noise[noise_idx]
            train_idx, val_idx = next(iter(
                    StratifiedShuffleSplit(n_splits=1, test_size=0.1,
                                        random_state=seed).split(XX_train_val, y_train_noise)))
            XX_train = XX_train_val[train_idx]
            y_train_correct = y_train_val[train_idx]
            y_train = y_train_noise[train_idx]
            X_val = XX_train_val[val_idx]
            y_val = y_train_noise[val_idx]
            y_val_correct = y_train_val[val_idx]
        else:
            train_idx, val_idx = next(iter(
                StratifiedShuffleSplit(n_splits=1, test_size=0.1,
                                        random_state=seed).split(XX_train_val, y_train_val)))
            XX_train = XX_train_val[train_idx]
            y_train = y_train_val[train_idx]
            y_train_correct = y_train_val[train_idx]
            X_val = XX_train_val[val_idx]
            y_val = y_train_val[val_idx]
            y_val_correct = y_train_val[val_idx]


        # val_size_ratio_of_train_val = 0.1 / (1 - 0.2) # (desired val ratio) / (1 - test ratio from first split)
        # XX_train, XX_val, y_train, y_val = train_test_split(
        #     XX_train_val, y_train_val, test_size=val_size_ratio_of_train_val, random_state=42, stratify=y_train_val
        # )
        print((XX_train.shape, y_train.shape, X_val.shape, y_val.shape,XX_test.shape, y_test.shape))

        ####################################################################################################

        """## **LSTM 2-Layers**"""

        epochs = 25
        emb_dim = 50
        batch_size = 128
        input_text_len = X_DeepLearning.shape[1]
        vocabulary_size = 15000
        model_lstm2 = create_lstm2_model(vocabulary_size, input_text_len, epochs, emb_dim, batch_size)
        model_lstm2.compile(optimizer=tf.optimizers.Adam(),loss=my_bitemp_loss, metrics=['acc'])
        print(model_lstm2.summary())

        #checkpoint_callback = ModelCheckpoint(filepath="lastm-2-layer-best_model.h5", save_best_only=True, monitor="val_acc", mode="max", verbose=1)

        early_stopping_callback = EarlyStopping(monitor="val_acc", mode="max", patience=10, verbose=1, restore_best_weights=True)

        reduce_lr_callback = ReduceLROnPlateau(monitor="val_loss", factor=0.1, patience=5, verbose=1, mode="min", min_delta=0.0001, cooldown=0, min_lr=0)

        history_lstm2 = model_lstm2.fit(XX_train, y_train,
                                        epochs=epochs,
                                        batch_size=batch_size,
                                        validation_data=(X_val,y_val),
                                        callbacks=[  reduce_lr_callback])

        results_2 = model_lstm2.evaluate(XX_test, y_test, verbose=False)
        print(f'Test results - Loss: {results_2[0]} - Accuracy: {100*results_2[1]}%')
        all_results.append(results_2[1])

    mean_accuracy = np.mean(all_results)
    std_accuracy = np.std(all_results)

    print(f"Mean accuracy: {mean_accuracy:.4f} +/- {std_accuracy:.4f}")